{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cae298b-d524-4f58-97d6-2457e41f04da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Important Note!\n",
    "\n",
    "This notebook ran using with a 12.2 LTS Runtime version!\n",
    "\n",
    "There are no concerns regarding cluster size (memory and cores).\n",
    "\n",
    "Insert `spark.databricks.delta.retentionDurationCheck.enabled false` during cluster configs creation to be able to use VACUUM properly in this notebook.\n",
    "\n",
    "The purpose of this notebook is just to show the version of the SQL commands for Python, **always use the SQL version as a reference**, as it was the one used during the Databricks SQL course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5905cc1b-12b4-4201-b2c1-98db61d3ed89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd571ed5-6f94-4937-a0b1-39093d419c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/</td><td>FileStore/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/</td><td>mnt/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/</td><td>user/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/",
         "FileStore/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/",
         "databricks-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-results/",
         "databricks-results/",
         0,
         0
        ],
        [
         "dbfs:/mnt/",
         "mnt/",
         0,
         0
        ],
        [
         "dbfs:/user/",
         "user/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4a97920-68c7-43b6-858b-4026cde6e839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/</td><td>FileStore/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/</td><td>mnt/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/</td><td>user/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/",
         "FileStore/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/",
         "databricks-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-results/",
         "databricks-results/",
         0,
         0
        ],
        [
         "dbfs:/mnt/",
         "mnt/",
         0,
         0
        ],
        [
         "dbfs:/user/",
         "user/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0f771ed-4e64-4f48-92cf-a030e3180313",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Some examples of DBFS Unix-Like Commands\n",
    "\n",
    "| Command | Result |\n",
    "|--------|--------|\n",
    "| `ls` | List the directory files. |\n",
    "| `mkdirs` | Create a new directory. |\n",
    "| `cp` | Able to copy files from one directory to another. |\n",
    "| `mv` | Able to move files from one directory to another. |\n",
    "| `rm` | Can remove a file from a path. |\n",
    "| `rm -r` | Recursively removes nested folders or files. |\n",
    "| `put` | Let you insert data or even create new data files. |\n",
    "| `head` | Allows file reading in the first rows. |\n",
    "| `mount` | Create a link between a workspace and cloud object storage. |\n",
    "| `secrets.get` | Collect a secret from a certain scope of Databricks Secrets. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53653966-fc9e-499a-a969-60d4299b87f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dfecc43-6776-45a7-875c-be5a831a97e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FSHandler in module dbruntime.dbutils object:\n\nclass FSHandler(builtins.object)\n |  FSHandler(fsutils, fsutils_parallel, dbcore, sc, entry_point, displayHTML)\n |  \n |  Methods defined here:\n |  \n |  __call__(self)\n |      Call self as a function.\n |  \n |  __init__(self, fsutils, fsutils_parallel, dbcore, sc, entry_point, displayHTML)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  cacheFiles = f_with_exception_handling(*args, **kwargs)\n |  \n |  cacheTable = f_with_exception_handling(*args, **kwargs)\n |  \n |  check_types(self, vars_and_types)\n |  \n |  cp = f_with_exception_handling(*args, **kwargs)\n |  \n |  create_list_from_jschema(self, jschema, create_obj_from_jschema)\n |  \n |  head = f_with_exception_handling(*args, **kwargs)\n |  \n |  help(self, method_name=None)\n |  \n |  ls = f_with_exception_handling(*args, **kwargs)\n |  \n |  mkdirs = f_with_exception_handling(*args, **kwargs)\n |  \n |  mount = f_with_exception_handling(*args, **kwargs)\n |  \n |  mounts = f_with_exception_handling(*args, **kwargs)\n |  \n |  mv = f_with_exception_handling(*args, **kwargs)\n |  \n |  prettify_exception_message(f)\n |      This is a decorator function that aims to properly display errors that happened on the\n |      Scala side. Without such handling, stack traces from Scala are displayed at the\n |      bottom of error output, and are easily missed. We fix this by catching Py4JJavaError\n |      and throwing another exception with the error message from Scala side.\n |  \n |  print_return(self, result)\n |  \n |  put = f_with_exception_handling(*args, **kwargs)\n |  \n |  refreshMounts = f_with_exception_handling(*args, **kwargs)\n |  \n |  rm = f_with_exception_handling(*args, **kwargs)\n |  \n |  should_use_parallel_dbutils_fs(self)\n |  \n |  uncacheFiles = f_with_exception_handling(*args, **kwargs)\n |  \n |  uncacheTable = f_with_exception_handling(*args, **kwargs)\n |  \n |  unmount = f_with_exception_handling(*args, **kwargs)\n |  \n |  updateMount = f_with_exception_handling(*args, **kwargs)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
     ]
    }
   ],
   "source": [
    "help(dbutils.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01358624-3f50-4038-859c-25bfeeaa2554",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res2: Boolean = true\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res2: Boolean = true\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs mkdirs /databricks_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16a4c6d-62ce-4806-abeb-5d6ddf9635c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /databricks_example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e29c1ec3-2bc1-4c32-b1e0-3e0a137442b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 110 bytes.\nOut[3]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.put(\"/databricks_example/data.csv\", \"\"\"Name, Age, Job\n",
    "Angelo, 25, Nurse\n",
    "Maria, 23, Architect\n",
    "Ronaldo, 33, Actor\n",
    "Jessica, 18, Student\n",
    "Mara, 27, Doctor\"\"\",\n",
    "True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "969b8467-2a0f-43bf-ac1a-490b0d1993c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks_example/data.csv</td><td>data.csv</td><td>110</td><td>1716034036000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks_example/data.csv",
         "data.csv",
         110,
         1716034036000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /databricks_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b36d344-e6f2-49d8-bee0-5a659f96175c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Name, Age, Job\n",
       "Angelo, 25, Nurse\n",
       "Maria, 23, Architect\n",
       "Ronaldo, 33, Actor\n",
       "Jessica, 18, Student\n",
       "Mara, 27, Doctor\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Name, Age, Job\nAngelo, 25, Nurse\nMaria, 23, Architect\nRonaldo, 33, Actor\nJessica, 18, Student\nMara, 27, Doctor\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs head /databricks_example/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adccf1b3-cd4d-4208-971c-bdecde3f24eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/</td><td>FileStore/</td><td>0</td><td>1694631178000</td></tr><tr><td>dbfs:/Volume/</td><td>Volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/Volumes/</td><td>Volumes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks_cc_example/</td><td>databricks_cc_example/</td><td>0</td><td>1694649911000</td></tr><tr><td>dbfs:/mnt/</td><td>mnt/</td><td>0</td><td>1694530632000</td></tr><tr><td>dbfs:/user/</td><td>user/</td><td>0</td><td>1693629492000</td></tr><tr><td>dbfs:/volume/</td><td>volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/volumes/</td><td>volumes/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/",
         "FileStore/",
         0,
         1694631178000
        ],
        [
         "dbfs:/Volume/",
         "Volume/",
         0,
         0
        ],
        [
         "dbfs:/Volumes/",
         "Volumes/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/",
         "databricks-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-results/",
         "databricks-results/",
         0,
         0
        ],
        [
         "dbfs:/databricks_cc_example/",
         "databricks_cc_example/",
         0,
         1694649911000
        ],
        [
         "dbfs:/mnt/",
         "mnt/",
         0,
         1694530632000
        ],
        [
         "dbfs:/user/",
         "user/",
         0,
         1693629492000
        ],
        [
         "dbfs:/volume/",
         "volume/",
         0,
         0
        ],
        [
         "dbfs:/volumes/",
         "volumes/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f323a93-720b-4b30-b100-57d5f682ed6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /mnt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d262cd69-4038-4c36-8724-9700433c9671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/Volumes</td><td>UnityCatalogVolumes</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td></td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td></td></tr><tr><td>/Volume</td><td>DbfsReserved</td><td></td></tr><tr><td>/volumes</td><td>DbfsReserved</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td></td></tr><tr><td>/volume</td><td>DbfsReserved</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/databricks-datasets",
         "databricks-datasets",
         ""
        ],
        [
         "/Volumes",
         "UnityCatalogVolumes",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         ""
        ],
        [
         "/databricks-results",
         "databricks-results",
         ""
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         ""
        ],
        [
         "/Volume",
         "DbfsReserved",
         ""
        ],
        [
         "/volumes",
         "DbfsReserved",
         ""
        ],
        [
         "/",
         "DatabricksRoot",
         ""
        ],
        [
         "/volume",
         "DbfsReserved",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs mounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae1c1dd7-ee95-491f-8828-fee8210e9221",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1371154657537257>:6\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m aws_bucket_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpublic-gov-data-db\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      4\u001B[0m mount_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms3_dbfs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 6\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms3a://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccess_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msecret_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maws_bucket_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmount_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
       "\n",
       "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o398.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:704)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1080)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:853)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1069)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:712)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:172)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:436)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:436)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:335)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:525)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:629)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:647)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:624)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:534)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:526)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:494)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:546)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:57)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:546)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:72)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:524)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:178)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:106)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:106)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:150)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:147)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:88)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:840)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-1371154657537257>:6\u001B[0m\n\u001B[1;32m      3\u001B[0m aws_bucket_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpublic-gov-data-db\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m mount_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms3_dbfs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 6\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms3a://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccess_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msecret_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maws_bucket_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmount_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    361\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n\n\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o398.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:704)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1080)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:853)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1069)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:712)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:172)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:436)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:436)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:335)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:525)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:629)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:647)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:624)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:534)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:526)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:494)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:546)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:57)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:546)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:72)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:524)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:178)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:106)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:106)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:150)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:147)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:88)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n",
       "errorSummary": "java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/s3_dbfs; nested exception is: ",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "access_key = dbutils.secrets.get(scope = \"aws\", key = \"aws-access-key\")\n",
    "secret_key = dbutils.secrets.get(scope = \"aws\", key = \"aws-secret-key\")\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\")\n",
    "aws_bucket_name = \"databricks-eng\"\n",
    "mount_name = \"s3_dbfs\"\n",
    "\n",
    "dbutils.fs.mount(f\"s3a://{access_key}:{encoded_secret_key}@{aws_bucket_name}\", f\"/mnt/{mount_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "767bc8e7-9f30-4b0d-a771-bda6556193b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/mnt/s3_dbfs</td><td>s3a://public-gov-data-db</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td>sse-s3</td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td>sse-s3</td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td>sse-s3</td></tr><tr><td>/</td><td>DatabricksRoot</td><td>sse-s3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/databricks-datasets",
         "databricks-datasets",
         ""
        ],
        [
         "/mnt/s3_dbfs",
         "s3a://public-gov-data-db",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         "sse-s3"
        ],
        [
         "/databricks-results",
         "databricks-results",
         "sse-s3"
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         "sse-s3"
        ],
        [
         "/",
         "DatabricksRoot",
         "sse-s3"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs mounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79474ab0-b003-466e-8595-5e8000ee45ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/s3_dbfs/remuneracao202311.csv</td><td>remuneracao202311.csv</td><td>89297725</td><td>1716016122000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/s3_dbfs/remuneracao202311.csv",
         "remuneracao202311.csv",
         89297725,
         1716016122000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /mnt/s3_dbfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffdb0a00-fab8-4b1d-9698-37e379080c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS remuneracao_\n",
    "USING csv\n",
    "OPTIONS (header \"true\",\n",
    "      delimiter ';',\n",
    "      encoding 'ISO-8859-1',\n",
    "      inferSchema \"true\",\n",
    "      path '/mnt/s3_dbfs/remuneracao202311.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c811ba-e538-4484-9945-91ef428ec850",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>NOME</td><td>string</td><td>null</td></tr><tr><td>CPF</td><td>string</td><td>null</td></tr><tr><td>ÓRGÃO</td><td>string</td><td>null</td></tr><tr><td>CARGO</td><td>string</td><td>null</td></tr><tr><td>FUNÇÃO</td><td>string</td><td>null</td></tr><tr><td>SITUAÇÃO</td><td>string</td><td>null</td></tr><tr><td>MÊS</td><td>int</td><td>null</td></tr><tr><td>ANO</td><td>int</td><td>null</td></tr><tr><td>CÓDIGO DO ÓRGÃO</td><td>int</td><td>null</td></tr><tr><td>MATRÍCULA</td><td>string</td><td>null</td></tr><tr><td>REMUNERAÇÃO BÁSICA</td><td>string</td><td>null</td></tr><tr><td>BENEFÍCIOS</td><td>string</td><td>null</td></tr><tr><td>VALOR DA FUNÇÃO</td><td>string</td><td>null</td></tr><tr><td>COMISSÃO CONSELHEIRO</td><td>string</td><td>null</td></tr><tr><td>HORA EXTRA</td><td>string</td><td>null</td></tr><tr><td>VERBAS EVENTUAIS</td><td>string</td><td>null</td></tr><tr><td>VERBAS JUDICIAIS</td><td>string</td><td>null</td></tr><tr><td>DESCONTOS A MAIOR</td><td>string</td><td>null</td></tr><tr><td>LICENÇA PRÊMIO</td><td>string</td><td>null</td></tr><tr><td>IRRF</td><td>string</td><td>null</td></tr><tr><td>SEG. SOCIAL</td><td>string</td><td>null</td></tr><tr><td>TETO REDUTOR</td><td>string</td><td>null</td></tr><tr><td>OUTROS RECEBIMENTOS</td><td>string</td><td>null</td></tr><tr><td>OUTROS DESCONTOS OBRIGATÓRIOS</td><td>string</td><td>null</td></tr><tr><td>PAGAMENTOS A MAIOR</td><td>string</td><td>null</td></tr><tr><td>BRUTO</td><td>string</td><td>null</td></tr><tr><td>LÍQUIDO</td><td>string</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "NOME",
         "string",
         null
        ],
        [
         "CPF",
         "string",
         null
        ],
        [
         "ÓRGÃO",
         "string",
         null
        ],
        [
         "CARGO",
         "string",
         null
        ],
        [
         "FUNÇÃO",
         "string",
         null
        ],
        [
         "SITUAÇÃO",
         "string",
         null
        ],
        [
         "MÊS",
         "int",
         null
        ],
        [
         "ANO",
         "int",
         null
        ],
        [
         "CÓDIGO DO ÓRGÃO",
         "int",
         null
        ],
        [
         "MATRÍCULA",
         "string",
         null
        ],
        [
         "REMUNERAÇÃO BÁSICA",
         "string",
         null
        ],
        [
         "BENEFÍCIOS",
         "string",
         null
        ],
        [
         "VALOR DA FUNÇÃO",
         "string",
         null
        ],
        [
         "COMISSÃO CONSELHEIRO",
         "string",
         null
        ],
        [
         "HORA EXTRA",
         "string",
         null
        ],
        [
         "VERBAS EVENTUAIS",
         "string",
         null
        ],
        [
         "VERBAS JUDICIAIS",
         "string",
         null
        ],
        [
         "DESCONTOS A MAIOR",
         "string",
         null
        ],
        [
         "LICENÇA PRÊMIO",
         "string",
         null
        ],
        [
         "IRRF",
         "string",
         null
        ],
        [
         "SEG. SOCIAL",
         "string",
         null
        ],
        [
         "TETO REDUTOR",
         "string",
         null
        ],
        [
         "OUTROS RECEBIMENTOS",
         "string",
         null
        ],
        [
         "OUTROS DESCONTOS OBRIGATÓRIOS",
         "string",
         null
        ],
        [
         "PAGAMENTOS A MAIOR",
         "string",
         null
        ],
        [
         "BRUTO",
         "string",
         null
        ],
        [
         "LÍQUIDO",
         "string",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE remuneracao_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70814701-ddfb-4bcc-891c-2549b368bcfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th></tr></thead><tbody><tr><td>csv</td><td>null</td><td>spark_catalog.default.remuneracao_</td><td></td><td>dbfs:/mnt/s3_dbfs/remuneracao202311.csv</td><td>2024-05-18T12:35:04.000+0000</td><td>null</td><td>List()</td><td>null</td><td>null</td><td>Map()</td><td>null</td><td>null</td><td>null</td><td>Map()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "csv",
         null,
         "spark_catalog.default.remuneracao_",
         "",
         "dbfs:/mnt/s3_dbfs/remuneracao202311.csv",
         "2024-05-18T12:35:04.000+0000",
         null,
         [],
         null,
         null,
         {},
         null,
         null,
         null,
         {}
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"long\",\"valueContainsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL remuneracao_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17068f0c-8728-4276-9396-9d8336732686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>NOME</td><td>string</td><td>null</td></tr><tr><td>CPF</td><td>string</td><td>null</td></tr><tr><td>ÓRGÃO</td><td>string</td><td>null</td></tr><tr><td>CARGO</td><td>string</td><td>null</td></tr><tr><td>FUNÇÃO</td><td>string</td><td>null</td></tr><tr><td>SITUAÇÃO</td><td>string</td><td>null</td></tr><tr><td>MÊS</td><td>int</td><td>null</td></tr><tr><td>ANO</td><td>int</td><td>null</td></tr><tr><td>CÓDIGO DO ÓRGÃO</td><td>int</td><td>null</td></tr><tr><td>MATRÍCULA</td><td>string</td><td>null</td></tr><tr><td>REMUNERAÇÃO BÁSICA</td><td>string</td><td>null</td></tr><tr><td>BENEFÍCIOS</td><td>string</td><td>null</td></tr><tr><td>VALOR DA FUNÇÃO</td><td>string</td><td>null</td></tr><tr><td>COMISSÃO CONSELHEIRO</td><td>string</td><td>null</td></tr><tr><td>HORA EXTRA</td><td>string</td><td>null</td></tr><tr><td>VERBAS EVENTUAIS</td><td>string</td><td>null</td></tr><tr><td>VERBAS JUDICIAIS</td><td>string</td><td>null</td></tr><tr><td>DESCONTOS A MAIOR</td><td>string</td><td>null</td></tr><tr><td>LICENÇA PRÊMIO</td><td>string</td><td>null</td></tr><tr><td>IRRF</td><td>string</td><td>null</td></tr><tr><td>SEG. SOCIAL</td><td>string</td><td>null</td></tr><tr><td>TETO REDUTOR</td><td>string</td><td>null</td></tr><tr><td>OUTROS RECEBIMENTOS</td><td>string</td><td>null</td></tr><tr><td>OUTROS DESCONTOS OBRIGATÓRIOS</td><td>string</td><td>null</td></tr><tr><td>PAGAMENTOS A MAIOR</td><td>string</td><td>null</td></tr><tr><td>BRUTO</td><td>string</td><td>null</td></tr><tr><td>LÍQUIDO</td><td>string</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>spark_catalog</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>remuneracao_</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Created Time</td><td>Sat May 18 12:35:04 UTC 2024</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark 3.3.2</td><td></td></tr><tr><td>Type</td><td>EXTERNAL</td><td></td></tr><tr><td>Provider</td><td>csv</td><td></td></tr><tr><td>Location</td><td>dbfs:/mnt/s3_dbfs/remuneracao202311.csv</td><td></td></tr><tr><td>Serde Library</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td></td></tr><tr><td>InputFormat</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td></td></tr><tr><td>OutputFormat</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td></td></tr><tr><td>Storage Properties</td><td>[encoding=ISO-8859-1, inferSchema=true, header=true, delimiter=;]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "NOME",
         "string",
         null
        ],
        [
         "CPF",
         "string",
         null
        ],
        [
         "ÓRGÃO",
         "string",
         null
        ],
        [
         "CARGO",
         "string",
         null
        ],
        [
         "FUNÇÃO",
         "string",
         null
        ],
        [
         "SITUAÇÃO",
         "string",
         null
        ],
        [
         "MÊS",
         "int",
         null
        ],
        [
         "ANO",
         "int",
         null
        ],
        [
         "CÓDIGO DO ÓRGÃO",
         "int",
         null
        ],
        [
         "MATRÍCULA",
         "string",
         null
        ],
        [
         "REMUNERAÇÃO BÁSICA",
         "string",
         null
        ],
        [
         "BENEFÍCIOS",
         "string",
         null
        ],
        [
         "VALOR DA FUNÇÃO",
         "string",
         null
        ],
        [
         "COMISSÃO CONSELHEIRO",
         "string",
         null
        ],
        [
         "HORA EXTRA",
         "string",
         null
        ],
        [
         "VERBAS EVENTUAIS",
         "string",
         null
        ],
        [
         "VERBAS JUDICIAIS",
         "string",
         null
        ],
        [
         "DESCONTOS A MAIOR",
         "string",
         null
        ],
        [
         "LICENÇA PRÊMIO",
         "string",
         null
        ],
        [
         "IRRF",
         "string",
         null
        ],
        [
         "SEG. SOCIAL",
         "string",
         null
        ],
        [
         "TETO REDUTOR",
         "string",
         null
        ],
        [
         "OUTROS RECEBIMENTOS",
         "string",
         null
        ],
        [
         "OUTROS DESCONTOS OBRIGATÓRIOS",
         "string",
         null
        ],
        [
         "PAGAMENTOS A MAIOR",
         "string",
         null
        ],
        [
         "BRUTO",
         "string",
         null
        ],
        [
         "LÍQUIDO",
         "string",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "spark_catalog",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "remuneracao_",
         ""
        ],
        [
         "Owner",
         "root",
         ""
        ],
        [
         "Created Time",
         "Sat May 18 12:35:04 UTC 2024",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark 3.3.2",
         ""
        ],
        [
         "Type",
         "EXTERNAL",
         ""
        ],
        [
         "Provider",
         "csv",
         ""
        ],
        [
         "Location",
         "dbfs:/mnt/s3_dbfs/remuneracao202311.csv",
         ""
        ],
        [
         "Serde Library",
         "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
         ""
        ],
        [
         "InputFormat",
         "org.apache.hadoop.mapred.SequenceFileInputFormat",
         ""
        ],
        [
         "OutputFormat",
         "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat",
         ""
        ],
        [
         "Storage Properties",
         "[encoding=ISO-8859-1, inferSchema=true, header=true, delimiter=;]",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql(\"DESCRIBE TABLE EXTENDED remuneracao_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bee04758-0d4d-488a-83a0-302c8b89942c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%fs` not found.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "<span class='ansi-red-fg'>UsageError</span>: Line magic function `%fs` not found.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dbutils.fs.unmount(/mnt/s3_dbfs)\n",
    "#%fs unmount /mnt/s3_dbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157e5c86-64ea-4c05-97e8-5ce6d68b38f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>NOME</th><th>CPF</th><th>ÓRGÃO</th><th>CARGO</th><th>FUNÇÃO</th><th>SITUAÇÃO</th><th>MÊS</th><th>ANO</th><th>CÓDIGO DO ÓRGÃO</th><th>MATRÍCULA</th><th>REMUNERAÇÃO BÁSICA</th><th>BENEFÍCIOS</th><th>VALOR DA FUNÇÃO</th><th>COMISSÃO CONSELHEIRO</th><th>HORA EXTRA</th><th>VERBAS EVENTUAIS</th><th>VERBAS JUDICIAIS</th><th>DESCONTOS A MAIOR</th><th>LICENÇA PRÊMIO</th><th>IRRF</th><th>SEG. SOCIAL</th><th>TETO REDUTOR</th><th>OUTROS RECEBIMENTOS</th><th>OUTROS DESCONTOS OBRIGATÓRIOS</th><th>PAGAMENTOS A MAIOR</th><th>BRUTO</th><th>LÍQUIDO</th></tr></thead><tbody><tr><td>DANIELA PERDIGAO MENESES LIMA                     </td><td>***766711**</td><td>SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                </td><td>ANALISTA PLANEJ. URB. INFRA.  </td><td>                                                            </td><td>ATIVO                         </td><td>11</td><td>2023</td><td>100004</td><td>01569163</td><td>12831,88</td><td>640,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>2047,66</td><td>1788,62</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>13471,88</td><td>9635,60</td></tr><tr><td>ELIETE FERREIRA DA SILVA GOES                     </td><td>***692721**</td><td>SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                </td><td>ANALISTA POL PUBL E GEST GOV  </td><td>ASSESSOR ESPECIAL                                           </td><td>ATIVO                         </td><td>11</td><td>2023</td><td>100004</td><td>01569228</td><td>9623,69</td><td>407,27</td><td>3915,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>2419,84</td><td>1331,63</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>13945,96</td><td>10194,49</td></tr><tr><td>PAULA ANDERSON DE MATOS EUSTAQUIO                 </td><td>***681091**</td><td>SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                </td><td>ANALISTA PLANEJ. URB. INFRA.  </td><td>                                                            </td><td>ATIVO                         </td><td>11</td><td>2023</td><td>100004</td><td>01569287</td><td>18748,95</td><td>640,00</td><td>,00</td><td>,00</td><td>,00</td><td>18748,95</td><td>,00</td><td>,00</td><td>,00</td><td>7098,32</td><td>5249,70</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>38137,90</td><td>25789,88</td></tr><tr><td>CARLOS RENATO COLEN DE MELO                       </td><td>***697806**</td><td>SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                </td><td>ANALISTA PLANEJ. URB. INFRA.  </td><td>ASSESSOR                                                    </td><td>ATIVO                         </td><td>11</td><td>2023</td><td>100004</td><td>01569295</td><td>17429,21</td><td>640,00</td><td>2940,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>4049,86</td><td>2424,40</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>21009,21</td><td>14534,95</td></tr><tr><td>ROBERTA RIBEIRO                                   </td><td>***831606**</td><td>SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                </td><td>ANALISTA PLANEJ. URB. INFRA.  </td><td>                                                            </td><td>ATIVO                         </td><td>11</td><td>2023</td><td>100004</td><td>0156935X</td><td>17611,02</td><td>640,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>3284,35</td><td>2449,86</td><td>,00</td><td>,00</td><td>,00</td><td>,00</td><td>18251,02</td><td>12516,81</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "DANIELA PERDIGAO MENESES LIMA                     ",
         "***766711**",
         "SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                ",
         "ANALISTA PLANEJ. URB. INFRA.  ",
         "                                                            ",
         "ATIVO                         ",
         11,
         2023,
         100004,
         "01569163",
         "12831,88",
         "640,00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         "2047,66",
         "1788,62",
         ",00",
         ",00",
         ",00",
         ",00",
         "13471,88",
         "9635,60"
        ],
        [
         "ELIETE FERREIRA DA SILVA GOES                     ",
         "***692721**",
         "SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                ",
         "ANALISTA POL PUBL E GEST GOV  ",
         "ASSESSOR ESPECIAL                                           ",
         "ATIVO                         ",
         11,
         2023,
         100004,
         "01569228",
         "9623,69",
         "407,27",
         "3915,00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         "2419,84",
         "1331,63",
         ",00",
         ",00",
         ",00",
         ",00",
         "13945,96",
         "10194,49"
        ],
        [
         "PAULA ANDERSON DE MATOS EUSTAQUIO                 ",
         "***681091**",
         "SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                ",
         "ANALISTA PLANEJ. URB. INFRA.  ",
         "                                                            ",
         "ATIVO                         ",
         11,
         2023,
         100004,
         "01569287",
         "18748,95",
         "640,00",
         ",00",
         ",00",
         ",00",
         "18748,95",
         ",00",
         ",00",
         ",00",
         "7098,32",
         "5249,70",
         ",00",
         ",00",
         ",00",
         ",00",
         "38137,90",
         "25789,88"
        ],
        [
         "CARLOS RENATO COLEN DE MELO                       ",
         "***697806**",
         "SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                ",
         "ANALISTA PLANEJ. URB. INFRA.  ",
         "ASSESSOR                                                    ",
         "ATIVO                         ",
         11,
         2023,
         100004,
         "01569295",
         "17429,21",
         "640,00",
         "2940,00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         "4049,86",
         "2424,40",
         ",00",
         ",00",
         ",00",
         ",00",
         "21009,21",
         "14534,95"
        ],
        [
         "ROBERTA RIBEIRO                                   ",
         "***831606**",
         "SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO E HABITACAO DO DF                ",
         "ANALISTA PLANEJ. URB. INFRA.  ",
         "                                                            ",
         "ATIVO                         ",
         11,
         2023,
         100004,
         "0156935X",
         "17611,02",
         "640,00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         ",00",
         "3284,35",
         "2449,86",
         ",00",
         ",00",
         ",00",
         ",00",
         "18251,02",
         "12516,81"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "NOME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CPF",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ÓRGÃO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CARGO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "FUNÇÃO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SITUAÇÃO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MÊS",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ANO",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "CÓDIGO DO ÓRGÃO",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "MATRÍCULA",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "REMUNERAÇÃO BÁSICA",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "BENEFÍCIOS",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "VALOR DA FUNÇÃO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "COMISSÃO CONSELHEIRO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "HORA EXTRA",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "VERBAS EVENTUAIS",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "VERBAS JUDICIAIS",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DESCONTOS A MAIOR",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LICENÇA PRÊMIO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "IRRF",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SEG. SOCIAL",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "TETO REDUTOR",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "OUTROS RECEBIMENTOS",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "OUTROS DESCONTOS OBRIGATÓRIOS",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "PAGAMENTOS A MAIOR",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "BRUTO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LÍQUIDO",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM remuneracao_ LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8decc3-d0f8-451d-a03e-feb63785e58c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "#FONTE DO DICIONÁRIO DE DADOS: http://dados.df.gov.br/dataset/462126f8-8a61-4cec-91a2-38615b7f70f6/resource/0514402e-cd29-440b-83e5-f97787dd1ad3/download/dicdadosremuneracaodosservidores.html\n",
    "spark.sql(\n",
    "\"CREATE TABLE IF NOT EXISTS remuneracao_geral (nome STRING COMMENT 'NOME COMPLETO DO SERVIDOR', \" + \\\n",
    "\"                                            cpf STRING COMMENT 'Nº DO CADASTRO DE PESSOA FÍSICA MASCARADO',\" + \\\n",
    "\"                                            orgao STRING COMMENT 'ÓRGÃO VINCULADO AO SERVIDOR',\" + \\\n",
    "\"                                            cargo STRING COMMENT 'POSIÇÃO QUE O SERVIDOR OCUPA NO ÓRGÃO DE FORMA PERMANENTE',\" + \\\n",
    "\"                                            funcao STRING COMMENT 'DESIGNAÇÃO TEMPORÁRIA PARA DESEMPENHO DE DETERMINADAS ATRIBUIÇÕES (CARGO COMISSIONADO)',\" + \\\n",
    "\"                                            situacao STRING COMMENT 'CONDIÇÃO DO SERVIDOR EM RELAÇÃO AO EXERCÍCIO DE SUAS ATIVIDADES',\" + \\\n",
    "\"                                            mes INTEGER COMMENT 'MÊS DE REFERÊNCIA',\" + \\\n",
    "\"                                            ano INTEGER COMMENT 'ANO DE REFERÊNCIA',\" + \\\n",
    "\"                                            codigo_do_orgao INTEGER COMMENT 'ÓRGÃO VINCULADO AO SERVIDOR',\" + \\\n",
    "\"                                            matricula STRING COMMENT 'MATRÍCULA DO SERVIDOR NO ÓRGÃO VINCULADO',\" + \\\n",
    "\"                                            remuneracao_basica STRING COMMENT 'REMUNERAÇÃO BÁSICA',\" + \\\n",
    "\"                                            beneficios STRING COMMENT 'VALOR DOS BENEFÍCIOS',\" + \\\n",
    "\"                                            valor_das_funcoes STRING COMMENT 'VALOR DAS FUNÇÕES',\" + \\\n",
    "\"                                            comissao_conselheiro STRING COMMENT 'COMISSÃO CONSELHEIRO',\" + \\\n",
    "\"                                            hora_extra STRING COMMENT 'TOTAL DE HORA EXTRA',\" + \\\n",
    "\"                                            verbas_eventuais STRING COMMENT 'VALOR DAS VERBAS EVENTUAIS',\" + \\\n",
    "\"                                            verbas_judiciais STRING COMMENT 'VALOR DAS VERBAS JUDICIAIS',\" + \\\n",
    "\"                                            descontos_a_maior STRING COMMENT 'VALOR DA REPOSIÇÃO DE DESCONTOS A MAIOR',\" + \\\n",
    "\"                                            licenca_premio STRING COMMENT 'VALOR DA LICENÇA PRÊMIO',\" + \\\n",
    "\"                                            irrf STRING COMMENT 'VALOR DO DESCONTO DE IMPOSTO DE RENDA RETIDO NA FONTE',\" + \\\n",
    "\"                                            seguridade_social STRING COMMENT 'VALOR DO DESCONTO DE SEGURIDADE SOCIAL',\" + \\\n",
    "\"                                            teto_redutor STRING COMMENT 'VALOR DO DESCONTO DE TETO REDUTOR',\" + \\\n",
    "\"                                            outros_recebimentos STRING COMMENT 'VALOR DE OUTROS RECEBIMENTOS',\" + \\\n",
    "\"                                            outros_descontos_obrigatorios STRING COMMENT 'VALOR DE OUTROS DESCONTOS OBRIGATÓRIOS',\" + \\\n",
    "\"                                            pagamento_a_maior STRING COMMENT 'VALOR DOS DESCONTOS DE PAGAMENTOS A MAIOR',\" + \\\n",
    "\"                                            bruto STRING COMMENT 'VALOR BRUTO DA REMUNERAÇÃO',\" + \\\n",
    "\"                                            liquido STRING COMMENT 'VALOR LÍQUIDO APÓS DESCONTOS OBRIGATÓRIOS')\" + \\\n",
    "\"COMMENT 'Este conjunto de dados apresenta a remuneração dos servidores do Governo do DF, detalhada por órgão e nome do servidor.'\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1371154657537266,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Explorer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
